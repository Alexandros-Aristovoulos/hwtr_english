{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import everything\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from numpy objects\n",
    "X_train = np.load('../my_dataset/X_train.npy')\n",
    "X_test = np.load('../my_dataset/X_test.npy')\n",
    "X_validate = np.load('../my_dataset/X_validate.npy')\n",
    "\n",
    "y_train = np.load('../my_dataset/y_train.npy')\n",
    "y_test = np.load('../my_dataset/y_test.npy')\n",
    "y_validate = np.load('../my_dataset/y_validate.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions from the runs (Iteration 2)\n",
    "\n",
    "### 1. Failure of the dense layer\n",
    "The memory capabilities provided by the dense layers has led to much worse results. All of the models with dense layers had a less than 40% accuracy. For the optimal model no dense layers will be used besides the final output layer. <br><br>\n",
    "<img src=\"iteration2_image_stats\\dense_layer_accuracy_FAIL.svg\">\n",
    "\n",
    "### 2. Best peforming models\n",
    "From the validation accuracy graph we see pretty similar results from the models with no dense layers. Here are the results on the 45th step: <br><br>\n",
    "<img src=\"iteration2_image_stats\\no_dense_layer_accuracy.svg\">\n",
    "| Model             | Validation accuracy   |\n",
    "| -----------       | -----------           |\n",
    "| 4-conv-32-nodes   | 89.38 %               |\n",
    "| 3-conv-64-nodes   | 88.75 %               |\n",
    "| 3-conv-48-nodes   | 88.13 %               |\n",
    "| 3-conv-32-nodes   | 88.13 %               |\n",
    "| 4-conv-48-nodes   | 87.50 %               |\n",
    "| 3-conv-16-nodes   | 86.25 %               |\n",
    "| 4-conv-64-nodes   | 85.00 %               |\n",
    "| 4-conv-16-nodes   | 78.75 %               |\n",
    "\n",
    "However, we should not draw conclusions just from the final step because the models seem to hit peak validation accuracy earlier and then they start to overfit. For this reasons let's check the graphs for 3 and 4 convolutional layers seperately.\n",
    "\n",
    "* #### 3 Convolutional layers <br>\n",
    "\n",
    "##### Accuracy\n",
    "<img src=\"iteration2_image_stats\\3_conv_layer_accuracy.svg\">\n",
    "\n",
    "##### Loss\n",
    "<img src=\"iteration2_image_stats\\3_conv_layer_loss.svg\">\n",
    "\n",
    "We can see that the best results for each model occur much earlier and at different points: <br>\n",
    "| Colour    | Step | Model              | Validation accuracy   |\n",
    "| --------- | ---- | ------             | -----------           |\n",
    "| Blue      | 16   | 3-conv-16-nodes    | 89.38 %               |\n",
    "| Cyan      | 26   | 3-conv-32-nodes    | 90.00 %               |\n",
    "| Green     | 16   | 3-conv-48-nodes    | 90.00 %               |\n",
    "| Orange    | 26   | 3-conv-64-nodes    | 89.38 %               |\n",
    "\n",
    "\n",
    "* #### 4 Convolutional layers <br>\n",
    "\n",
    "##### Accuracy\n",
    "<img src=\"iteration2_image_stats\\4_conv_layer_accuracy.svg\">\n",
    "\n",
    "##### Loss\n",
    "<img src=\"iteration2_image_stats\\4_conv_layer_loss.svg\">\n",
    "\n",
    "We can see that the best results for each model occur much earlier and at different points: <br>\n",
    "| Colour    | Step | Model              | Validation accuracy   |\n",
    "| --------- | ---- | ------             | -----------           |\n",
    "| Orange    | 32   | 4-conv-16-nodes    | 81.88 %               |\n",
    "| Pink      | 39   | 4-conv-32-nodes    | 90.00 %               |\n",
    "| Green     | 16   | 4-conv-48-nodes    | 90.00 %               |\n",
    "| Blue      | 17   | 4-conv-64-nodes    | 89.38 %               |\n",
    "\n",
    "\n",
    "By grouping the charts by number of convolutional layers we can safely conclude that: <br>\n",
    "* The best results are with 32 and 48 convolutional nodes\n",
    "* It is now necessary to implement dropout and early stopping to prevent over fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [0, 1]\n",
    "dense_nodes = [8, 16, 24]\n",
    "\n",
    "\n",
    "conv_layers = [3, 4]\n",
    "conv_nodes = [16, 32, 48, 64]\n",
    "epochs = 45\n",
    "\n",
    "# zero dense layers\n",
    "for conv_layer in conv_layers:\n",
    "    for conv_node in conv_nodes:\n",
    "        NAME = \"{}-conv-{}-convNodes-{}-dense-{}-denseNodes-{}\".format(conv_layer, conv_node, 0, 0, int(time.time()))\n",
    "        print(NAME)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(conv_node, (3, 3), input_shape=X_train.shape[1:]))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        for l in range(conv_layer-1):\n",
    "            model.add(Conv2D(conv_node, (3, 3)))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "\n",
    "        # output layer (as big as the number of words we teach)\n",
    "        output_neurons = len(np.unique(y_train))\n",
    "        model.add(tf.keras.layers.Dense(output_neurons, activation=tf.nn.softmax))\n",
    "\n",
    "        tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "        model.compile(loss='sparse_categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        model.fit(X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                validation_data=(X_validate, y_validate),\n",
    "                callbacks=[tensorboard])\n",
    "\n",
    "        # save the model\n",
    "        model.save(\"models/\"+NAME)\n",
    "\n",
    "# one dense layer\n",
    "for conv_layer in conv_layers:\n",
    "    for conv_node in conv_nodes:\n",
    "        for dense_node in dense_nodes:\n",
    "            NAME = \"{}-conv-{}-convNodes-{}-dense-{}-denseNodes-{}\".format(conv_layer, conv_node, 1, dense_node, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(conv_node, (3, 3), input_shape=X_train.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(conv_node, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            # smaller dense layer\n",
    "            model.add(tf.keras.layers.Dense(dense_node, activation=tf.nn.softmax))\n",
    "\n",
    "            # output layer (as big as the number of words we teach)\n",
    "            output_neurons = len(np.unique(y_train))\n",
    "            model.add(tf.keras.layers.Dense(output_neurons, activation=tf.nn.softmax))\n",
    "\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "            model.compile(loss='sparse_categorical_crossentropy',\n",
    "                        optimizer='adam',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "            model.fit(X_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_validate, y_validate),\n",
    "                    callbacks=[tensorboard])\n",
    "\n",
    "            # save the model\n",
    "            model.save(\"models/\"+NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99aa377fbfe6babaa8f85c06716341a20688fb45a5f56fcc96594486c2d6abfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
