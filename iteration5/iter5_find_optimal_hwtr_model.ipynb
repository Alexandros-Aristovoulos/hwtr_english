{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import everything\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential, optimizers\n",
    "from keras.layers import Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "import time\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from numpy objects\n",
    "X_train = np.load('../my_dataset/X_train.npy')\n",
    "X_test = np.load('../my_dataset/X_test.npy')\n",
    "X_validate = np.load('../my_dataset/X_validate.npy')\n",
    "\n",
    "y_train = np.load('../my_dataset/y_train.npy')\n",
    "y_test = np.load('../my_dataset/y_test.npy')\n",
    "y_validate = np.load('../my_dataset/y_validate.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = 3\n",
    "conv_nodes = 48\n",
    "epochs = 200\n",
    "early_stops = 6\n",
    "repeats = 5\n",
    "\n",
    "dropout = 0.25\n",
    "batches = [16, 32, 64, 128, 256]\n",
    "# equal dropout\n",
    "for batch in batches:\n",
    "    for i in range (repeats):\n",
    "        NAME = \"model-{}-batch-{}\".format(i, batch)\n",
    "        print(NAME)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(conv_nodes, (3, 3), input_shape=X_train.shape[1:]))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        for l in range(conv_layers-1):\n",
    "            model.add(Conv2D(conv_nodes, (3, 3)))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Flatten())\n",
    "\n",
    "        # output layer (as big as the number of words we teach)\n",
    "        output_neurons = len(np.unique(y_train))\n",
    "        model.add(tf.keras.layers.Dense(output_neurons, activation=tf.nn.softmax))\n",
    "\n",
    "        tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "\n",
    "        model.compile(loss='sparse_categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'],\n",
    "                    )\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor='val_accuracy', patience=early_stops, restore_best_weights=True), tensorboard]\n",
    "\n",
    "        model.fit(X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                validation_data=(X_validate, y_validate),\n",
    "                callbacks=callbacks,\n",
    "                batch_size=batch)\n",
    "\n",
    "            # save the model\n",
    "        model.save(\"models/\"+NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = np.zeros((len(batches), repeats))\n",
    "average_accuracies = np.zeros(len(batches))\n",
    "\n",
    "index=0\n",
    "for batch in batches:\n",
    "    for i in range (repeats):\n",
    "        NAME = \"model-{}-batch-{}\".format(i, batch)\n",
    "        model = tf.keras.models.load_model(\"models/\"+NAME)\n",
    "        accuracies[index][i] = round(model.evaluate(X_validate, y_validate)[1] * 100, 2)\n",
    "        average_accuracies[index] += accuracies[index][i]\n",
    "    index+=1\n",
    "\n",
    "average_accuracies = average_accuracies/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"|Batch size| Model 0 | Model 1 | Model 2 | Model 3 | Model 4 | Average |\")\n",
    "print(\"| -------- | ------- | ------- | ------- | ------- | ------- | ------- |\")\n",
    "index=0\n",
    "for batch in batches:\n",
    "    print(\"| Batch \"+str(batches[index])+\" | \"+str(accuracies[index][0])+\" | \"+str(accuracies[index][1])+\" | \"+str(accuracies[index][2])+\n",
    "    \" | \"+str(accuracies[index][3])+\" | \"+str(accuracies[index][4])+\" | \"+ str(average_accuracies[index])+\" | \")\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Batch size| Model 0 | Model 1 | Model 2 | Model 3 | Model 4 | Average |\n",
    "| -------- | ------- | ------- | ------- | ------- | ------- | ------- |\n",
    "| Batch 16 | 92.5 | 92.5 | 93.75 | 92.5 | 93.12 | 92.874 | \n",
    "| Batch 32 | 90.62 | 94.38 | 91.87 | 93.12 | 93.12 | 92.622 | \n",
    "| Batch 64 | 91.25 | 93.12 | 91.87 | 90.62 | 93.75 | 92.122 | \n",
    "| Batch 128 | 91.87 | 91.25 | 90.0 | 95.63 | 91.25 | 92.0 | \n",
    "| Batch 256 | 86.87 | 91.87 | 91.87 | 91.25 | 89.38 | 90.248 | "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99aa377fbfe6babaa8f85c06716341a20688fb45a5f56fcc96594486c2d6abfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
