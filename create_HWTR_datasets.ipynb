{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import everything\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATASET_BASE_PATH = \"Dataset\"\n",
    "BASE_IMAGE_PATH = os.path.join(DATASET_BASE_PATH, \"words\")\n",
    "IMAGE_WIDTH = 80\n",
    "IMAGE_HEIGHT = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lines that contain data about the words\n",
    "def get_usefull_lines():\n",
    "    words_list = []\n",
    "\n",
    "    # Remove useless lines\n",
    "    words = open(f\"{DATASET_BASE_PATH}/words.txt\", \"r\").readlines()\n",
    "    for line in words:\n",
    "\n",
    "        # Remove initial comments\n",
    "        if line[0] == \"#\":\n",
    "            continue\n",
    "\n",
    "        # Remove errored entries\n",
    "        if line.split(\" \")[1] != \"err\":\n",
    "            words_list.append(line)\n",
    "            \n",
    "    return words_list\n",
    "\n",
    "words_list = get_usefull_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths_and_labels(samples):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    for (i, file_line) in enumerate(samples):\n",
    "        line_split = file_line.strip()\n",
    "        line_split = line_split.split(\" \")\n",
    "\n",
    "        # Each line split will have this format for the corresponding image:\n",
    "        # part1/part1-part2/part1-part2-part3.png\n",
    "        image_name = line_split[0]\n",
    "        partI = image_name.split(\"-\")[0]\n",
    "        partII = image_name.split(\"-\")[1]\n",
    "        img_path = os.path.join(\n",
    "            BASE_IMAGE_PATH, partI, partI + \"-\" + partII, image_name + \".png\"\n",
    "        )\n",
    "        if os.path.getsize(img_path):\n",
    "            paths.append(img_path)\n",
    "            labels.append(file_line.split(\"\\n\")[0])\n",
    "\n",
    "    return paths, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_labels(labels):\n",
    "    cleaned_labels = []\n",
    "    for label in labels:\n",
    "        label = label.split(\" \")[-1].strip()\n",
    "        cleaned_labels.append(label)\n",
    "    return np.asarray(cleaned_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordsThatAppearBetween(listL, more_than, less_than):\n",
    "    unique, counts = np.unique(listL, return_counts=True)\n",
    "    x = dict(zip(unique, counts))\n",
    "    return [key for key, value in x.items() if value <= less_than and value >= more_than]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_lines(word_dictionary, listL):\n",
    "    words_list = []\n",
    "    for line in listL:\n",
    "\n",
    "        if line.split(\" \")[-1].strip() in word_dictionary:\n",
    "            words_list.append(line)\n",
    "\n",
    "    return words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the required numer of appearances here\n",
    "words_list = get_usefull_lines()\n",
    "all_cleaned_labels = clean_labels(words_list)\n",
    "\n",
    "# decide on the sample\n",
    "print(\"Total sample:\", len(all_cleaned_labels))\n",
    "print(\"Total unique words:\", len(np.unique(all_cleaned_labels)))\n",
    "\n",
    "print(\"Total words with more than 100 appearances:\", \n",
    "    len(getWordsThatAppearBetween(all_cleaned_labels, 100, len(all_cleaned_labels))))\n",
    "    \n",
    "word_dictionary = getWordsThatAppearBetween(all_cleaned_labels, 110, 150)\n",
    "print(\"Total words with appearances between 110 and 150:\", len(word_dictionary))\n",
    "print(word_dictionary)\n",
    "\n",
    "# uncomment and edit the following line to change the required range for the number of \n",
    "# appearances of a word in order to add it to the dataset\n",
    "# word_dictionary = getWordsThatAppearBetween(all_cleaned_labels, more_than, less_than) \n",
    "\n",
    "# use only the words that appear the required amount of times\n",
    "words_list = get_final_lines(word_dictionary, words_list)\n",
    "print(\"Final sample\", len(words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(words_list):\n",
    "    split_idx = int(0.9 * len(words_list))\n",
    "    train_samples = words_list[:split_idx]\n",
    "    test_samples = words_list[split_idx:]\n",
    "\n",
    "    val_split_idx = int(0.5 * len(test_samples))\n",
    "    validation_samples = test_samples[:val_split_idx]\n",
    "    test_samples = test_samples[val_split_idx:]\n",
    "\n",
    "    assert len(words_list) == len(train_samples) + len(validation_samples) + len(\n",
    "        test_samples\n",
    "    )\n",
    "\n",
    "    return train_samples, validation_samples, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the lines\n",
    "np.random.shuffle(words_list)\n",
    "\n",
    "# split the dataset\n",
    "train_samples, validation_samples, test_samples = split_dataset(words_list)\n",
    "\n",
    "# get labels and image paths\n",
    "train_img_paths, train_labels = get_image_paths_and_labels(train_samples)\n",
    "validation_img_paths, validation_labels = get_image_paths_and_labels(validation_samples)\n",
    "test_img_paths, test_labels = get_image_paths_and_labels(test_samples)\n",
    "\n",
    "# print statistics\n",
    "print(f\"Total training samples: {len(train_samples)}\")\n",
    "print(f\"Total validation samples: {len(validation_samples)}\")\n",
    "print(f\"Total test samples: {len(test_samples)}\")\n",
    "\n",
    "# get the cleaned labels in arrays\n",
    "train_labels = clean_labels(train_labels)\n",
    "validation_labels = clean_labels(validation_labels)\n",
    "test_labels = clean_labels(test_labels)\n",
    "\n",
    "# save the data up to now\n",
    "# labels\n",
    "labels_and_paths_location = 'labels_and_paths/'\n",
    "np.save(labels_and_paths_location + 'train_labels.npy', train_labels)\n",
    "np.save(labels_and_paths_location + 'validation_labels.npy', validation_labels)\n",
    "np.save(labels_and_paths_location + 'test_labels.npy', test_labels)\n",
    "# paths\n",
    "np.save(labels_and_paths_location + 'train_img_paths.npy', train_img_paths)\n",
    "np.save(labels_and_paths_location + 'validation_img_paths.npy', validation_img_paths)\n",
    "np.save(labels_and_paths_location + 'test_img_paths.npy', test_img_paths)\n",
    "\n",
    "model_dictionary = np.unique(train_labels)\n",
    "np.save(labels_and_paths_location + 'model_dictionary.npy', model_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from here if you want to have the same dataset as me\n",
    "# read the data\n",
    "# labels\n",
    "labels_and_paths_location = 'labels_and_paths/'\n",
    "train_labels = np.load(labels_and_paths_location + 'train_labels.npy')\n",
    "validation_labels = np.load(labels_and_paths_location + 'validation_labels.npy')\n",
    "test_labels = np.load(labels_and_paths_location + 'test_labels.npy')\n",
    "# paths\n",
    "train_img_paths = np.load(labels_and_paths_location + 'train_img_paths.npy')\n",
    "validation_img_paths = np.load(labels_and_paths_location + 'validation_img_paths.npy')\n",
    "test_img_paths = np.load(labels_and_paths_location + 'test_img_paths.npy')\n",
    "\n",
    "model_dictionary = np.load(labels_and_paths_location + 'model_dictionary.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image without distorting it\n",
    "def resize_image(img, size=(IMAGE_WIDTH, IMAGE_HEIGHT)):\n",
    "    h, w = img.shape[:2]\n",
    "    c = img.shape[2] if len(img.shape)>2 else 1\n",
    "    if h == w: \n",
    "        return cv2.resize(img, size, cv2.INTER_AREA)\n",
    "    dif = h if h > w else w\n",
    "    interpolation = cv2.INTER_AREA if dif > (size[0]+size[1])//2 else cv2.INTER_CUBIC\n",
    "    x_pos = (dif - w)//2\n",
    "    y_pos = (dif - h)//2\n",
    "    if len(img.shape) == 2:\n",
    "        mask = np.ones((dif, dif), dtype=img.dtype)\n",
    "        mask = cv2.bitwise_not(mask)               # Added mask inversion here\n",
    "        mask[y_pos:y_pos+h, x_pos:x_pos+w] = img[:h, :w]\n",
    "    else:\n",
    "        mask = np.ones((dif, dif, c), dtype=img.dtype)\n",
    "        mask = cv2.bitwise_not(mask)               # Added mask inversion here\n",
    "        mask[y_pos:y_pos+h, x_pos:x_pos+w, :] = img[:h, :w, :]\n",
    "    return cv2.resize(mask, size, interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference between original and resized pictures\n",
    "img_array = cv2.imread(train_img_paths[10], cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "print(train_labels[10])\n",
    "plt.imshow(img_array, cmap='gray')  # graph it\n",
    "plt.show()\n",
    "img_array = resize_image(img_array)\n",
    "plt.imshow(img_array, cmap='gray')  # graph it\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(img_paths, labels):\n",
    "    dataset = []\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    for index, path in enumerate(img_paths):\n",
    "        # convert to array\n",
    "        img_array = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  \n",
    "        # resize to normalize data size\n",
    "        img_array = resize_image(img_array)  \n",
    "        # find the first occurence of the word in the uniquel labels list\n",
    "        unique_label_index = np.where(unique_labels == labels[index])[0][0]\n",
    "        # normalise the colours of the image \n",
    "        img_array = tf.keras.utils.normalize(img_array, axis=1)\n",
    "        dataset.append([img_array, unique_label_index])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tha data into numpy objects to save time\n",
    "def save_datasets(img_paths, labels, save_name):\n",
    "    dataset = create_dataset(img_paths, labels) \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for features, label in dataset:\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "\n",
    "    # keras need the features to be the correct shape\n",
    "    X = np.array(X).reshape(-1, IMAGE_WIDTH, IMAGE_HEIGHT, 1)\n",
    "    file_name = save_name + '.npy'\n",
    "    np.save('my_dataset/X_'+ file_name, X)\n",
    "    np.save('my_dataset/y_'+ file_name, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_datasets(train_img_paths, train_labels, 'train')\n",
    "save_datasets(test_img_paths, test_labels, 'test')\n",
    "save_datasets(validation_img_paths, validation_labels, 'validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from numpy objects\n",
    "X_train = np.load('my_dataset/X_train.npy')\n",
    "X_test = np.load('my_dataset/X_test.npy')\n",
    "X_validate = np.load('my_dataset/X_validate.npy')\n",
    "\n",
    "y_train = np.load('my_dataset/y_train.npy')\n",
    "y_test = np.load('my_dataset/y_test.npy')\n",
    "y_validate = np.load('my_dataset/y_validate.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check an object from the dataset\n",
    "unique_train_labels = np.unique(train_labels)\n",
    "print(unique_train_labels[[y_train[10]]])\n",
    "plt.imshow(X_train[10], cmap='gray')  # graph it\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99aa377fbfe6babaa8f85c06716341a20688fb45a5f56fcc96594486c2d6abfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
